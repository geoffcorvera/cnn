{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "catdog.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1DTMD1xpRXsLgB9pYFumEUIvo009xgsNJ",
      "authorship_tag": "ABX9TyMApt0ObzEYEeP01ddGj288",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geoffcorvera/cnn/blob/colab/catdog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5ESCOtfvM_z"
      },
      "source": [
        "Build model on top of CNN pre-trained on ImageNet dataset. The final classification layer contains a single neuron with output in range [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxo6jC0KtwUm"
      },
      "source": [
        "import os\n",
        "import numpy as np \n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from keras import models\n",
        "from keras import layers"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k27Ev1ArFi_B",
        "outputId": "970b75be-4b4b-41ab-fa72-160ddc695b82"
      },
      "source": [
        "# Confirm TPU connection\n",
        "import tensorflow as tf \n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print(f'Found GPU at: {device_name}')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE9KxubI-Fvg",
        "outputId": "06d4e62d-94d4-4060-840c-d50e0e56629e"
      },
      "source": [
        "# Load resnet pretrained on ImageNet\n",
        "pre_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
        "pre_model.trainable = False"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxoMrp7As3ze"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize inception resnet first layer filters\n",
        "def getConvLayer(model):\n",
        "  res = None\n",
        "  for layer in model.layers:\n",
        "    if 'conv' in layer.name:\n",
        "      res = layer\n",
        "      break\n",
        "  return res\n",
        "\n",
        "def visualizeFilters(filters):\n",
        "  # filters = filters[0]\n",
        "  nf = filters.shape[3]\n",
        "  fig, _ = plt.subplots(4,8)\n",
        "  \n",
        "  for i, ax in enumerate(fig.axes):\n",
        "    ax.imshow(filters[:,:,:,i])\n",
        "    ax.set_axis_off()\n",
        "  fig.suptitle('1st Convolution Layer Filters')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "conv_layer = getConvLayer(pre_model)\n",
        "filters = conv_layer.get_weights()\n",
        "visualizeFilters(conv_layer.get_weights()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQMCbqpc0KWt",
        "outputId": "a8898b9e-39fe-401c-c97b-b0bb69759e76"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers.experimental import preprocessing as preprocessing_layers\n",
        "\n",
        "print('Building model...\\n')\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "      preprocessing_layers.RandomFlip('horizontal'),\n",
        "      preprocessing_layers.RandomRotation(0.1),\n",
        "      preprocessing_layers.RandomZoom(0.1),\n",
        "    ]\n",
        ")\n",
        "\n",
        "input_shape = (150,150,3)\n",
        "inputs = keras.Input(shape=input_shape)\n",
        "x = data_augmentation(inputs)           #Augment data to increase training set\n",
        "x = preprocessing_layers.Rescaling(1.0/255)(x) #Rescale image values to [0,1]\n",
        "\n",
        "outputs = pre_model(x)\n",
        "outputs = layers.Flatten()(outputs)\n",
        "outputs = layers.Dense(256, activation='relu')(outputs)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(outputs)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model...\n",
            "\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "rescaling (Rescaling)        (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "inception_resnet_v2 (Functio (None, 3, 3, 1536)        54336736  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 13824)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               3539200   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 57,876,193\n",
            "Trainable params: 3,539,457\n",
            "Non-trainable params: 54,336,736\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhw3dducvMmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "842db4ab-6742-45e1-db5a-afa8d7d7b673"
      },
      "source": [
        "import tensorflow.keras.preprocessing as preprocessing\n",
        "from google.colab import drive\n",
        "\n",
        "print('Importing training and test datasets...\\n')\n",
        "train_path = r'/content/drive/MyDrive/Spring2021/Deep Learning & Computer Vision/p3_data/cats_dogs_dataset/dataset/training_set'\n",
        "train_ds = preprocessing.image_dataset_from_directory(train_path, image_size=(150,150))\n",
        "# train_ds = train_ds.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "test_path = r'/content/drive/MyDrive/Spring2021/Deep Learning & Computer Vision/p3_data/cats_dogs_dataset/dataset/test_set (1)'\n",
        "test_ds = preprocessing.image_dataset_from_directory(test_path, image_size=(150,150))\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Importing training and test datasets...\n",
            "\n",
            "Found 8282 files belonging to 2 classes.\n",
            "Found 2003 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpOLl6TbEeAY"
      },
      "source": [
        "# Train\n",
        "The model is compiled with RMSprop optimizer and binary cross-entropy loss function.\n",
        "\n",
        "Training continues for 3 epochs, with 0.2% of the training set used for validation to check generalization.\n",
        "\n",
        "Weights are saved periodically during training to the \"training\" directory. When model fitting is complete, the model is saved to \"last_trained\" directory for future use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1cahjH-_POA",
        "outputId": "2df62e39-6e79-40d7-e218-7fc620cd7540"
      },
      "source": [
        "checkpoint_path = r'/content/drive/MyDrive/Spring2021/Deep Learning & Computer Vision/training'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
        "print('Fitting to data...\\n')\n",
        "history = model.fit(train_ds,\n",
        "                    epochs=3,\n",
        "                    callbacks=[cp_callback],\n",
        "                    validation_split=0.2)\n",
        "\n",
        "os.listdir(checkpoint_dir)\n",
        "\n",
        "save_path = r'/content/drive/MyDrive/Spring2021/Deep Learning & Computer Vision/last_trained'\n",
        "model.save(save_path)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting to data...\n",
            "\n",
            "Epoch 1/3\n",
            "259/259 [==============================] - 2040s 8s/step - loss: 0.2507\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/Spring2021/Deep Learning & Computer Vision/training\n",
            "Epoch 2/3\n",
            "259/259 [==============================] - 39s 149ms/step - loss: 0.1776\n",
            "\n",
            "Epoch 00002: saving model to /content/drive/MyDrive/Spring2021/Deep Learning & Computer Vision/training\n",
            "Epoch 3/3\n",
            "259/259 [==============================] - 39s 150ms/step - loss: 0.1455\n",
            "\n",
            "Epoch 00003: saving model to /content/drive/MyDrive/Spring2021/Deep Learning & Computer Vision/training\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Spring2021/Deep Learning & Computer Vision/saved_models/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeDGEWGkQpN3",
        "outputId": "d63abd4e-81a5-4951-93f0-3454cffe36fa"
      },
      "source": [
        "print('Evaluating against test...\\n')\n",
        "results = model.evaluate(test_ds)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating against test...\n",
            "\n",
            "63/63 [==============================] - 495s 7s/step - loss: 0.0777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IosjrCQadOXN",
        "outputId": "4294ddbf-539d-4b5d-b96c-74ca4fe9f867"
      },
      "source": [
        "test_labels = np.concatenate([y.numpy() for _,y in test_ds])\n",
        "\n",
        "y_pred = model.predict(test_ds).reshape(-1)\n",
        "y_pred = np.where(y_pred>0.9, 1, 0).astype(int) #threshold at 0.9\n",
        "\n",
        "assert y_pred.shape == test_labels.shape"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cats', 'dogs']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVotnjQfjKlh",
        "outputId": "4cb9e0a7-5bcf-4581-a08d-0b0c3a004886"
      },
      "source": [
        "from tensorflow.math import confusion_matrix\n",
        "\n",
        "con_mat = confusion_matrix(labels=test_labels, predictions=y_pred).numpy()\n",
        "print(con_mat)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[541 459]\n",
            " [533 470]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}